{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d07d25",
   "metadata": {},
   "source": [
    "### HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8168414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A for  loop is used to loop through the different cross-validation sets\n",
    "for i in range(1,6):\n",
    "    #########################################\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.python.keras.layers import Dense, Flatten\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "#Create the data loaders\n",
    "    \n",
    "    train_ds = keras.utils.image_dataset_from_directory(\n",
    "        directory=r'D:\\Gaussian_blur_bicubic_interpolation\\Classification\\HR\\{}\\train'.format(i),\n",
    "        labels='inferred',\n",
    "        label_mode='binary',\n",
    "        batch_size=32,\n",
    "        color_mode=\"rgb\",\n",
    "        seed=123,\n",
    "        image_size=(240, 240))\n",
    "\n",
    "\n",
    "    test_ds = keras.utils.image_dataset_from_directory(\n",
    "        directory=r'D:\\Gaussian_blur_bicubic_interpolation\\Classification\\HR\\{}\\test'.format(i),\n",
    "        labels='inferred',\n",
    "        label_mode='binary',\n",
    "        batch_size=32,\n",
    "        color_mode=\"rgb\",\n",
    "        seed=123,\n",
    "        image_size=(240, 240))\n",
    "\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    #Create the ResNet and train it with early stopping, the best performing modefl after 40 epochs is saved\n",
    "    \n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Flatten, Dense, Input\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    \n",
    "    input_tensor = Input(shape=(240, 240, 3))\n",
    "    pretrained_model = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        weights='imagenet',\n",
    "        input_tensor=input_tensor\n",
    "    )\n",
    "\n",
    "    x = pretrained_model.output\n",
    "    x = Flatten()(x)\n",
    "    output_tensor = Dense(1, activation='sigmoid')(x)\n",
    "    resnet_model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    resnet_model.compile(optimizer=SGD(learning_rate=0.01),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=40,  restore_best_weights=True)\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"HR_best_model.weights.hdf5\", \n",
    "                    monitor=\"val_accuracy\", mode=\"max\", \n",
    "                    save_best_only=True, verbose=1)\n",
    "\n",
    "    history = resnet_model.fit(train_ds, epochs=40, callbacks=[callback, checkpoint], validation_data = test_ds, verbose=0)\n",
    "    \n",
    "    resnet_model.load_weights(\"HR_best_model.weights.hdf5\")\n",
    "\n",
    "    ##################################################\n",
    "    import numpy as np\n",
    "\n",
    "    #Calculate the predications on the test\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for img, labels in test_ds:\n",
    "        group_labels = resnet_model.predict(img,verbose=0)\n",
    "        for label in group_labels.tolist():\n",
    "            y_pred.append(np.round(label[0]))\n",
    "        labels = labels.numpy()\n",
    "        for label in labels.tolist():\n",
    "            y_true.append(label[0])\n",
    "\n",
    "    ###################################################\n",
    "    import csv\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Save values to CSV file\n",
    "    header = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "    data = [accuracy, precision, recall, f1]\n",
    "\n",
    "    csv_filename = 'performance_metrics\\HR\\cross_validation_{}_results.csv'.format(i)\n",
    "\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "        writer.writerow(data)\n",
    "\n",
    "    print(f'Metrics saved to {csv_filename}')\n",
    "\n",
    "    ##################################################\n",
    "    #Saving epoch and accuracy results into  a csv file\n",
    "    counter = 1\n",
    "    Accuracy = []\n",
    "    Epoch = []\n",
    "    Val_accuracy = []\n",
    "\n",
    "    for value in history.history['accuracy']:\n",
    "        Accuracy.append(round(value,2))\n",
    "        Epoch.append(counter)\n",
    "        counter += 1\n",
    "\n",
    "    for value in history.history['val_accuracy']:\n",
    "        Val_accuracy.append((round(value,2)))\n",
    "\n",
    "    import csv\n",
    "\n",
    "    csv_file = 'Epoch_SR_results\\HR\\cross_validation_{}_epcoch_SR_results.csv'.format(i)\n",
    "\n",
    "    # Combine the two lists into a list of tuples\n",
    "    data = zip(Epoch, Accuracy, Val_accuracy)\n",
    "\n",
    "    # Write to the CSV file\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writerow(['Epoch', 'Accuracy', 'Val_accuracy'])\n",
    "\n",
    "        # Write the data\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f'CSV file \"{csv_file}\" created successfully.')\n",
    "\n",
    "\n",
    "########################################################\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#Calculating the confusion matrix for the last cross-validation set.\n",
    "matrix = confusion_matrix(y_pred,y_true)\n",
    " \n",
    "#Computing the confusion matrix.\n",
    "sns.heatmap(matrix, \n",
    "            annot=True,\n",
    "            fmt='g', \n",
    "            xticklabels=['HGG', 'LGG'],\n",
    "            yticklabels=['HGG','LGG'])\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.savefig('HR_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46957655",
   "metadata": {},
   "source": [
    "###  SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1644b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5,6):\n",
    "    #########################################\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.python.keras.layers import Dense, Flatten\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "    train_ds = keras.utils.image_dataset_from_directory(\n",
    "        directory=r'D:\\Gaussian_blur_bicubic_interpolation\\Classification\\SR\\{}\\train'.format(i),\n",
    "        labels='inferred',\n",
    "        label_mode='binary',\n",
    "        batch_size=32,\n",
    "        color_mode=\"rgb\",\n",
    "        seed=123,\n",
    "        image_size=(240, 240))\n",
    "\n",
    "\n",
    "    test_ds = keras.utils.image_dataset_from_directory(\n",
    "        directory=r'D:\\Gaussian_blur_bicubic_interpolation\\Classification\\SR\\{}\\test'.format(i),\n",
    "        labels='inferred',\n",
    "        label_mode='binary',\n",
    "        batch_size=32,\n",
    "        color_mode=\"rgb\",\n",
    "        seed=123,\n",
    "        image_size=(240, 240))\n",
    "\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Flatten, Dense, Input\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    \n",
    "    input_tensor = Input(shape=(240, 240, 3))\n",
    "    pretrained_model = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        weights='imagenet',\n",
    "        input_tensor=input_tensor\n",
    "    )\n",
    "\n",
    "    x = pretrained_model.output\n",
    "    x = Flatten()(x)\n",
    "    output_tensor = Dense(1, activation='sigmoid')(x)\n",
    "    resnet_model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    resnet_model.compile(optimizer=SGD(learning_rate=0.01),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=40,  restore_best_weights=True)\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"SR_best_model.weights.hdf5\", \n",
    "                    monitor=\"val_accuracy\", mode=\"max\", \n",
    "                    save_best_only=True, verbose=1)\n",
    "\n",
    "    history = resnet_model.fit(train_ds, epochs=40, callbacks=[callback, checkpoint], validation_data = test_ds, verbose=0)\n",
    "    \n",
    "    resnet_model.load_weights(\"SR_best_model.weights.hdf5\")\n",
    "\n",
    "    ##################################################\n",
    "    import numpy as np\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for img, labels in test_ds:\n",
    "        group_labels = resnet_model.predict(img,verbose=0)\n",
    "        for label in group_labels.tolist():\n",
    "            y_pred.append(np.round(label[0]))\n",
    "        labels = labels.numpy()\n",
    "        for label in labels.tolist():\n",
    "            y_true.append(label[0])\n",
    "\n",
    "    ###################################################\n",
    "    import csv\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Save values to CSV file\n",
    "    header = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "    data = [accuracy, precision, recall, f1]\n",
    "\n",
    "    csv_filename = 'performance_metrics\\SR\\cross_validation_{}_results.csv'.format(i)\n",
    "\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "        writer.writerow(data)\n",
    "\n",
    "    print(f'Metrics saved to {csv_filename}')\n",
    "\n",
    "    ##################################################\n",
    "    #Saving epoch and accuracy results into  a csv file\n",
    "    counter = 1\n",
    "    Accuracy = []\n",
    "    Epoch = []\n",
    "    Val_accuracy = []\n",
    "\n",
    "    for value in history.history['accuracy']:\n",
    "        Accuracy.append(round(value,2))\n",
    "        Epoch.append(counter)\n",
    "        counter += 1\n",
    "\n",
    "    for value in history.history['val_accuracy']:\n",
    "        Val_accuracy.append((round(value,2)))\n",
    "\n",
    "    import csv\n",
    "\n",
    "    csv_file = 'Epoch_SR_results\\SR\\cross_validation_{}_epcoch_SR_results.csv'.format(i)\n",
    "\n",
    "    # Combine the two lists into a list of tuples\n",
    "    data = zip(Epoch, Accuracy, Val_accuracy)\n",
    "\n",
    "    # Write to the CSV file\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writerow(['Epoch', 'Accuracy', 'Val_accuracy'])\n",
    "\n",
    "        # Write the data\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f'CSV file \"{csv_file}\" created successfully.')\n",
    "\n",
    "\n",
    "########################################################\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#Calculating the confusion matrix.\n",
    "matrix = confusion_matrix(y_pred,y_true)\n",
    " \n",
    "#Computing the confusion matrix.\n",
    "sns.heatmap(matrix, \n",
    "            annot=True,\n",
    "            fmt='g', \n",
    "            xticklabels=['HGG', 'LGG'],\n",
    "            yticklabels=['HGG','LGG'])\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.savefig('SR_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf93240",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ccfe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    #########################################\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.python.keras.layers import Dense, Flatten\n",
    "    from tensorflow.keras.models import Sequential, Model\n",
    "    from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "    train_ds = keras.utils.image_dataset_from_directory(\n",
    "        directory=r'D:\\Gaussian_blur_bicubic_interpolation\\Classification\\LR\\{}\\train'.format(i),\n",
    "        labels='inferred',\n",
    "        label_mode='binary',\n",
    "        batch_size=32,\n",
    "        color_mode=\"rgb\",\n",
    "        seed=123,\n",
    "        image_size=(60, 60))\n",
    "\n",
    "\n",
    "    test_ds = keras.utils.image_dataset_from_directory(\n",
    "        directory=r'D:\\Gaussian_blur_bicubic_interpolation\\Classification\\LR\\{}\\test'.format(i),\n",
    "        labels='inferred',\n",
    "        label_mode='binary',\n",
    "        batch_size=32,\n",
    "        color_mode=\"rgb\",\n",
    "        seed=123,\n",
    "        image_size=(60, 60))\n",
    "\n",
    "\n",
    "\n",
    "    ###############################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Flatten, Dense, Input\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    \n",
    "    input_tensor = Input(shape=(60, 60, 3))\n",
    "    pretrained_model = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        pooling='avg',\n",
    "        weights='imagenet',\n",
    "        input_tensor=input_tensor\n",
    "    )\n",
    "\n",
    "    x = pretrained_model.output\n",
    "    x = Flatten()(x)\n",
    "    output_tensor = Dense(1, activation='sigmoid')(x)\n",
    "    resnet_model = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "    for layer in pretrained_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    resnet_model.compile(optimizer=SGD(learning_rate=0.01),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=40,  restore_best_weights=True)\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"LR_best_model.weights.hdf5\", \n",
    "                    monitor=\"val_accuracy\", mode=\"max\", \n",
    "                    save_best_only=True, verbose=1)\n",
    "\n",
    "    history = resnet_model.fit(train_ds, epochs=40, callbacks=[callback, checkpoint], validation_data = test_ds, verbose=0)\n",
    "    \n",
    "    resnet_model.load_weights(\"LR_best_model.weights.hdf5\")\n",
    "\n",
    "    ##################################################\n",
    "    import numpy as np\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for img, labels in test_ds:\n",
    "        group_labels = resnet_model.predict(img,verbose=0)\n",
    "        for label in group_labels.tolist():\n",
    "            y_pred.append(np.round(label[0]))\n",
    "        labels = labels.numpy()\n",
    "        for label in labels.tolist():\n",
    "            y_true.append(label[0])\n",
    "\n",
    "    ###################################################\n",
    "    import csv\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Save values to CSV file\n",
    "    header = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "    data = [accuracy, precision, recall, f1]\n",
    "\n",
    "    csv_filename = 'performance_metrics\\LR\\cross_validation_{}_results.csv'.format(i)\n",
    "\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "        writer.writerow(data)\n",
    "\n",
    "    print(f'Metrics saved to {csv_filename}')\n",
    "\n",
    "    ##################################################\n",
    "    #Saving epoch and accuracy results into  a csv file\n",
    "    counter = 1\n",
    "    Accuracy = []\n",
    "    Epoch = []\n",
    "    Val_accuracy = []\n",
    "\n",
    "    for value in history.history['accuracy']:\n",
    "        Accuracy.append(round(value,2))\n",
    "        Epoch.append(counter)\n",
    "        counter += 1\n",
    "\n",
    "    for value in history.history['val_accuracy']:\n",
    "        Val_accuracy.append((round(value,2)))\n",
    "\n",
    "    import csv\n",
    "\n",
    "    csv_file = 'Epoch_SR_results\\LR\\cross_validation_{}_epcoch_SR_results.csv'.format(i)\n",
    "\n",
    "    # Combine the two lists into a list of tuples\n",
    "    data = zip(Epoch, Accuracy, Val_accuracy)\n",
    "\n",
    "    # Write to the CSV file\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writerow(['Epoch', 'Accuracy', 'Val_accuracy'])\n",
    "\n",
    "        # Write the data\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f'CSV file \"{csv_file}\" created successfully.')\n",
    "\n",
    "\n",
    "########################################################\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#Calculating the confusion matrix.\n",
    "matrix = confusion_matrix(y_pred,y_true)\n",
    " \n",
    "#Computing the confusion matrix.\n",
    "sns.heatmap(matrix, \n",
    "            annot=True,\n",
    "            fmt='g', \n",
    "            xticklabels=['HGG', 'LGG'],\n",
    "            yticklabels=['HGG','LGG'])\n",
    "plt.ylabel('Prediction',fontsize=13)\n",
    "plt.xlabel('Actual',fontsize=13)\n",
    "plt.title('Confusion Matrix',fontsize=17)\n",
    "plt.savefig('LR_plot.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
